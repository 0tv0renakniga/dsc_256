{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ad6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "import numpy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d759b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81325322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat(d, catID, maxLength, includeCat = True, includeReview = True, includeLength = True):\n",
    "    feat = []\n",
    "    if includeCat:\n",
    "        # My implementation is modular such that this one function concatenates all three features together,\n",
    "        # depending on which are selected\n",
    "    if includeReview:\n",
    "        #\n",
    "    if includeLength:\n",
    "        #\n",
    "    return feat + [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ada384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(reg, catID, dataTrain, dataValid, dataTest, includeCat=True, includeReview=True, includeLength=True):\n",
    "    mod = linear_model.LogisticRegression(C=reg, class_weight='balanced')\n",
    "\n",
    "    maxLength = max([len(d['review/text']) for d in dataTrain])\n",
    "    \n",
    "    Xtrain = [feat(d, catID, maxLength, includeCat, includeReview, includeLength) for d in dataTrain]\n",
    "    Xvalid = [feat(d, catID, maxLength, includeCat, includeReview, includeLength) for d in dataValid]\n",
    "    Xtest = [feat(d, catID, maxLength, includeCat, includeReview, includeLength) for d in dataTest]\n",
    "    \n",
    "    yTrain = [d['beer/ABV'] > 7 for d in dataTrain]\n",
    "    yValid = [d['beer/ABV'] > 7 for d in dataValid]\n",
    "    yTest = [d['beer/ABV'] > 7 for d in dataTest]\n",
    "    \n",
    "    # (1) Fit the model on the training set\n",
    "    # (2) Compute validation BER\n",
    "    # (3) Compute test BER\n",
    "\n",
    "    return mod, vBER, tBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460933e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08711296",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f872f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1(catID, dataTrain, dataValid, dataTest):\n",
    "    # No need to modify this if you've implemented the functions above\n",
    "    mod, validBER, testBER = pipeline(10, catID, dataTrain, dataValid, dataTest, True, False, False)\n",
    "    return mod, validBER, testBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84af258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf88be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd1768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q2(catID, dataTrain, dataValid, dataTest):\n",
    "    mod, validBER, testBER = pipeline(10, catID, dataTrain, dataValid, dataTest, True, True, True)\n",
    "    return mod, validBER, testBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7adad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda7330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8985755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q3(catID, dataTrain, dataValid, dataTest):\n",
    "    # Your solution here...\n",
    "    for c in [0.001, 0.01, 0.1, 1, 10]:\n",
    "        #\n",
    "    # Return the validBER and testBER for the model that works best on the validation set\n",
    "    return mod, validBER, testBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52688b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af37382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c66382ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q4(C, catID, dataTrain, dataValid, dataTest):\n",
    "    mod, validBER, testBER_noCat = pipeline(C, catID, dataTrain, dataValid, dataTest, False, True, True)\n",
    "    mod, validBER, testBER_noReview = pipeline(C, catID, dataTrain, dataValid, dataTest, True, False, True)\n",
    "    mod, validBER, testBER_noLength = pipeline(C, catID, dataTrain, dataValid, dataTest, True, True, False)\n",
    "    return testBER_noCat, testBER_noReview, testBER_noLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b763d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbd21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024a628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    # Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94773001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(i, N, usersPerItem):\n",
    "    # Implement...\n",
    "\n",
    "    # Should be a list of (similarity, itemID) pairs\n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66772f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d18b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71fc4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, ypred):\n",
    "    # Implement..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf535d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanRating(dataTrain):\n",
    "    # Implement...\n",
    "\n",
    "def getUserAverages(itemsPerUser, ratingDict):\n",
    "    # Implement (should return a dictionary mapping users to their averages)\n",
    "    return userAverages\n",
    "\n",
    "def getItemAverages(usersPerItem, ratingDict):\n",
    "    # Implement...\n",
    "    return itemAverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929248fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9fa7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRating(user,item,ratingMean,reviewsPerUser,usersPerItem,itemsPerUser,userAverages,itemAverages):\n",
    "    # Solution for Q6, should return a rating\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608092c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7afad6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b64e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRatingQ7(user,item,ratingMean,reviewsPerUser,usersPerItem,itemsPerUser,userAverages,itemAverages):\n",
    "    # Your solution here\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f4384a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
