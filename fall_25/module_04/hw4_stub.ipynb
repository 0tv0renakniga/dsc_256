{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import math\n",
    "import numpy\n",
    "import random\n",
    "import sklearn\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import linear_model\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, y):\n",
    "    diffs = [(a-b)**2 for (a,b) in zip(predictions, y)]\n",
    "    return sum(diffs)/len(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts(dataset):\n",
    "    # Your solution here\n",
    "    \n",
    "    # Return word lists. Bigrams should be strings with a space in the middle, e.g. \"like this\"\n",
    "    return mostCommonUnigrams, mostCommonBigrams, mostCommonBoth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum, wordId, wordSet, which):\n",
    "    # \"which\" is one of \"unigrams\", \"bigrams\", or \"both\"\n",
    "    feat = [0]*len(wordSet)\n",
    "\n",
    "    # Your solution here\n",
    "    \n",
    "    # Do not include an offset term, it'll be done by the library\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModel(wList, which, dataset):\n",
    "    wordId = dict(zip(wList, range(len(wList))))\n",
    "    wordSet = set(wList)\n",
    "    \n",
    "    # Your solution here\n",
    "\n",
    "    # clf = the model\n",
    "    return clf, theta, predictions, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DF(dataset, wordSet):\n",
    "    df = defaultdict(int)\n",
    "    \n",
    "    # Dictionary of document frequencies for words in wordset. Convert to lower case and remove punctuation.\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(query, wordSet):\n",
    "    tf = defaultdict(int)\n",
    "    \n",
    "    # Dictionary of term frequencies for the query, and words in wordset.\n",
    "    # Convert to lower case and remove punctuation.\n",
    "    # TFs should be binary (i.e., 1 if the word is present), not counts\n",
    "    \n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(query, df, dataset, wordSet):\n",
    "    tf = TF(query, wordSet)\n",
    "    tfidfQuery = [tf[w] * math.log2(len(dataset) / df[w]) for w in wordSet]\n",
    "    return tfidfQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine(x1,x2):\n",
    "    numer = 0\n",
    "    norm1 = 0\n",
    "    norm2 = 0\n",
    "    for a1,a2 in zip(x1,x2):\n",
    "        numer += a1*a2\n",
    "        norm1 += a1**2\n",
    "        norm2 += a2**2\n",
    "    if norm1*norm2:\n",
    "        return numer / math.sqrt(norm1*norm2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarities(query, dataset, wordSet):\n",
    "    similarities = []\n",
    "    \n",
    "    # Vector of cosine similarity, review pairs.\n",
    "    # Should preserve the ordering of the original dataset, though skipping the query review if present.\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeUserSentences(dataset):\n",
    "    # For every user, make a \"sentence\" (a list of item IDs) containing their user history, ordered by time\n",
    "    # dateutil.parser is available on the autograder if you want to use it to process temporal data\n",
    "    # Returned value should be a list of lists of book_ids\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeWVmodel(sentences):\n",
    "    random.seed(0)\n",
    "    model10 = Word2Vec(sentences,\n",
    "                     min_count=1, # Words/items with fewer instances are discarded\n",
    "                     vector_size=10, # Model dimensionality\n",
    "                     window=3, # Window size\n",
    "                     sg=1) # Skip-gram model\n",
    "    return model10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRating(user, item, model10, ratingMean, itemAverages, reviewsPerUser):\n",
    "    # reviewsPerUser maps a user ID to a list of their reviews\n",
    "    # itemAverages contains the average rating for each item\n",
    "    # ratingMean is the global average (all above provided by the runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betterPredictRating(user, item, model10, ratingMean, itemAverages, reviewsPerUser):\n",
    "    # Fix the above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
