{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1db2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm # Import tqdm for progress bars\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "# Enable tqdm for pandas operations\n",
    "tqdm.pandas()\n",
    "\n",
    "# ==========================================\n",
    "# 1. PURE CONTENT FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "def prepare_content_features(df, is_train=True, tfidf_model=None, scaler_model=None):\n",
    "    \"\"\"\n",
    "    Engineers features using only Pandas/Numpy/Sklearn.\n",
    "    Separates fitting (Train) from transforming (Test) to prevent leakage.\n",
    "    \"\"\"\n",
    "    print(f\"   -> Feature Engineering (Train Context: {is_train})...\")\n",
    "    \n",
    "    # --- A. Text Features (TF-IDF) ---\n",
    "    # We use a slightly smaller vocab to keep MLP training fast on CPU\n",
    "    txt = df['text'].fillna('none').astype(str)\n",
    "    \n",
    "    if is_train:\n",
    "        print(\"      -> Fitting TF-IDF (This may take a moment)...\")\n",
    "        # No tqdm here as fit_transform is atomic in sklearn\n",
    "        tfidf_model = TfidfVectorizer(max_features=2000, stop_words='english', ngram_range=(1, 2))\n",
    "        X_text = tfidf_model.fit_transform(txt).toarray() # Dense for MLP\n",
    "    else:\n",
    "        print(\"      -> Transforming Text...\")\n",
    "        X_text = tfidf_model.transform(txt).toarray()\n",
    "\n",
    "    # --- B. Metadata Features ---\n",
    "    if 'date' in df.columns:\n",
    "        dt = pd.to_datetime(df['date'], errors='coerce')\n",
    "        year = dt.dt.year.fillna(2015) - 2000\n",
    "        month = dt.dt.month.fillna(1)\n",
    "        day_of_week = dt.dt.dayofweek.fillna(0)\n",
    "        is_weekend = (day_of_week >= 5).astype(float)\n",
    "    else:\n",
    "        year, month, day_of_week, is_weekend = 0, 0, 0, 0\n",
    "\n",
    "    # Use progress_apply to show a bar for this operation\n",
    "    print(\"      -> Calculating Review Lengths...\")\n",
    "    review_len = df['text'].fillna('').progress_apply(len)\n",
    "    found_funny = df['found_funny'].fillna(0)\n",
    "    \n",
    "    # Handle compensation safely\n",
    "    if 'compensation' in df.columns:\n",
    "        compensation = (df['compensation'] == 'Recorded Free').astype(float)\n",
    "    else:\n",
    "        compensation = np.zeros(len(df))\n",
    "\n",
    "    # Stack Meta Features\n",
    "    # Note: We use numpy stack for efficiency\n",
    "    X_meta_raw = np.column_stack([\n",
    "        year, month, day_of_week, is_weekend,\n",
    "        review_len, found_funny, compensation\n",
    "    ])\n",
    "    \n",
    "    # Scale Meta Features\n",
    "    if is_train:\n",
    "        scaler_model = StandardScaler()\n",
    "        X_meta = scaler_model.fit_transform(X_meta_raw)\n",
    "    else:\n",
    "        X_meta = scaler_model.transform(X_meta_raw)\n",
    "        \n",
    "    # --- Combine ---\n",
    "    # Concatenate Text (2000 cols) + Meta (7 cols)\n",
    "    X_final = np.hstack([X_text, X_meta])\n",
    "    \n",
    "    return X_final, tfidf_model, scaler_model\n",
    "\n",
    "# ==========================================\n",
    "# 2. MODEL DEFINITION\n",
    "# ==========================================\n",
    "def build_ensemble_model():\n",
    "    \"\"\"\n",
    "    Instead of relying on just one NN, we ensemble two powerful sklearn models.\n",
    "    1. MLPRegressor (Deep Learning)\n",
    "    2. HistGradientBoostingRegressor (The 'Kaggle Winner' algorithm)\n",
    "    \"\"\"\n",
    "    print(\"   -> Building Ensemble (MLP + Gradient Boosting)...\")\n",
    "    \n",
    "    # Model 1: Deep Neural Network (mimics the TensorFlow architecture)\n",
    "    # hidden_layer_sizes=(512, 256, 64) is roughly equivalent to the TF model\n",
    "    mlp = MLPRegressor(\n",
    "        hidden_layer_sizes=(512, 256, 64),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.0001, # L2 regularization\n",
    "        batch_size=128,\n",
    "        learning_rate='adaptive',\n",
    "        learning_rate_init=0.001,\n",
    "        early_stopping=True, # Critical for preventing overfitting\n",
    "        validation_fraction=0.1,\n",
    "        n_iter_no_change=5,\n",
    "        max_iter=50, # Epochs\n",
    "        random_state=42,\n",
    "        verbose=True # Prints iteration progress\n",
    "    )\n",
    "    \n",
    "    # Model 2: Histogram-based Gradient Boosting\n",
    "    # This is typically FASTER and MORE ACCURATE for tabular data than NNs\n",
    "    gbm = HistGradientBoostingRegressor(\n",
    "        max_iter=200,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=10,\n",
    "        l2_regularization=0.1,\n",
    "        early_stopping=True,\n",
    "        random_state=42,\n",
    "        verbose=1 # Prints iteration progress (Scoring...)\n",
    "    )\n",
    "    \n",
    "    # Ensemble: Average the predictions of both\n",
    "    ensemble = VotingRegressor(\n",
    "        estimators=[('mlp', mlp), ('gbm', gbm)],\n",
    "        weights=[0.4, 0.6] # Giving slightly more weight to GBM as it's usually more robust\n",
    "    )\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION UTILITIES\n",
    "# ==========================================\n",
    "def readJSON(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        d = eval(l)\n",
    "        yield d\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Sklearn Content-Based Pipeline...\")\n",
    "    \n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        train_data = []\n",
    "        # We strictly ignore ID logic here as requested\n",
    "        # Added tqdm to visualize data loading speed\n",
    "        print(\"Loading Data from disk...\")\n",
    "        for d in tqdm(readJSON(\"train.json.gz\"), desc=\"Reading Lines\"):\n",
    "            train_data.append(d)\n",
    "\n",
    "        df = pd.DataFrame(train_data)\n",
    "        \n",
    "        # Basic cleanup\n",
    "        if 'found_funny' not in df.columns: df['found_funny'] = 0\n",
    "        if 'compensation' not in df.columns: df['compensation'] = 'None'\n",
    "        df['found_funny'] = df['found_funny'].fillna(0)\n",
    "        df['compensation'] = df['compensation'].fillna('None')\n",
    "        df['hours'] = df['hours'].fillna(0)\n",
    "        df['hours_transformed'] = np.log2(df['hours'] + 1)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: train.json.gz not found. Creating dummy data...\")\n",
    "        df = pd.DataFrame({\n",
    "            'hours_transformed': np.random.uniform(0, 14, 5000),\n",
    "            'text': ['this game is amazing and addictive' if i%2==0 else 'boring refund' for i in range(5000)],\n",
    "            'date': ['2020-01-01']*5000,\n",
    "            'found_funny': [0]*5000,\n",
    "            'compensation': ['None']*5000\n",
    "        })\n",
    "\n",
    "    # 2. Split\n",
    "    # We split BEFORE feature engineering to simulate real world train/test separation\n",
    "    y = df['hours_transformed'].values\n",
    "    train_df, val_df, y_train, y_val = train_test_split(df, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    print(f\"Train samples: {len(train_df)}, Val samples: {len(val_df)}\")\n",
    "\n",
    "    # 3. Feature Engineering\n",
    "    # Fit on Train\n",
    "    X_train, tfidf, scaler = prepare_content_features(train_df, is_train=True)\n",
    "    # Transform Val\n",
    "    X_val, _, _ = prepare_content_features(val_df, is_train=False, tfidf_model=tfidf, scaler_model=scaler)\n",
    "    \n",
    "    # 4. Train Ensemble\n",
    "    model = build_ensemble_model()\n",
    "    \n",
    "    print(\"\\nTraining Ensemble Model (Logs will appear for each iteration)...\")\n",
    "    # Note: MLP in sklearn is verbose=True, so you'll see loss logs\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 5. Evaluation\n",
    "    print(\"\\n--- Evaluation ---\")\n",
    "    val_preds = model.predict(X_val)\n",
    "    \n",
    "    # Clip predictions to valid range\n",
    "    val_preds = np.clip(val_preds, 0, None)\n",
    "    \n",
    "    rmse = np.sqrt(np.mean((y_val - val_preds)**2))\n",
    "    print(f\"FINAL RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    # Bias Check\n",
    "    val_df_res = val_df.copy()\n",
    "    val_df_res['pred'] = val_preds\n",
    "    val_df_res['error'] = val_df_res['hours_transformed'] - val_df_res['pred']\n",
    "    val_df_res['bin'] = pd.cut(val_df_res['hours_transformed'], bins=[0,2,4,6,8,10,20])\n",
    "    \n",
    "    print(\"\\nBias by Target Bin:\")\n",
    "    print(val_df_res.groupby('bin', observed=False)['error'].mean())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"       MODEL CONFIGURATION SUMMARY       \")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Input Features:      {X_train.shape[1]} (TF-IDF + Metadata)\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Algorithm 1: MLPRegressor (Deep Learning)\")\n",
    "    print(\"  - Layers: (512, 256, 64)\")\n",
    "    print(\"  - Activation: ReLU\")\n",
    "    print(\"  - Solver: Adam\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Algorithm 2: HistGradientBoostingRegressor\")\n",
    "    print(\"  - Max Depth: 10\")\n",
    "    print(\"  - Learning Rate: 0.1\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Ensemble Weight:     40% MLP / 60% Gradient Boosting\")\n",
    "    print(f\"Final RMSE:          {rmse:.4f}\")\n",
    "    print(\"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a9dce3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Text Processing (TF-IDF + SVD) ---\n",
      "   -> Compressing Text features via SVD...\n",
      "--- 2. Date Processing ---\n",
      "--- 3. Basic Counts ---\n",
      "Train size: 148750, Val size: 26250\n",
      "--- 4. Computing Target Statistics (No Leakage) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_id             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_id             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_emb            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">429,440</span> │ user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_emb            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">155,968</span> │ item_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ item_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ flatten_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_features      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">197</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                     │                   │            │ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">101,376</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_id             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_id             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_emb            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │    \u001b[38;5;34m429,440\u001b[0m │ user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_emb            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │    \u001b[38;5;34m155,968\u001b[0m │ item_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ item_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ flatten_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ flatten_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_features      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m197\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                     │                   │            │ dense_features[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m101,376\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">854,209</span> (3.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m854,209\u001b[0m (3.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">852,673</span> (3.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m852,673\u001b[0m (3.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Wide & Deep Model...\n",
      "Epoch 1/25\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - loss: 3.4805 - mae: 1.4115 - val_loss: 4.0669 - val_mae: 1.5555 - learning_rate: 5.0000e-04\n",
      "Epoch 2/25\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 2.8766 - mae: 1.2871 - val_loss: 3.3672 - val_mae: 1.3924 - learning_rate: 5.0000e-04\n",
      "Epoch 3/25\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 2.7601 - mae: 1.2552 - val_loss: 3.4669 - val_mae: 1.4175 - learning_rate: 5.0000e-04\n",
      "Epoch 4/25\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - loss: 2.6627 - mae: 1.2293 - val_loss: 3.3281 - val_mae: 1.3790 - learning_rate: 5.0000e-04\n",
      "Epoch 5/25\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - loss: 2.5422 - mae: 1.1981 - val_loss: 3.2938 - val_mae: 1.3711 - learning_rate: 5.0000e-04\n",
      "Epoch 6/25\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - loss: 2.2525 - mae: 1.1248 - val_loss: 3.4809 - val_mae: 1.4091 - learning_rate: 5.0000e-04\n",
      "Epoch 7/25\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 1.6157 - mae: 0.9530 - val_loss: 3.5304 - val_mae: 1.4029 - learning_rate: 5.0000e-04\n",
      "Epoch 8/25\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - loss: 1.0036 - mae: 0.7504 - val_loss: 3.6771 - val_mae: 1.4319 - learning_rate: 2.5000e-04\n",
      "Epoch 9/25\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - loss: 0.7936 - mae: 0.6651 - val_loss: 3.7541 - val_mae: 1.4466 - learning_rate: 2.5000e-04\n",
      "\n",
      "--- Evaluation ---\n",
      "\u001b[1m821/821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "FINAL RMSE: 1.8127\n",
      "\n",
      "Bias by Target Bin:\n",
      "bin\n",
      "(0, 2]     -0.876833\n",
      "(2, 4]      0.321291\n",
      "(4, 6]      1.128998\n",
      "(6, 8]      2.111627\n",
      "(8, 10]     3.299577\n",
      "(10, 20]    4.879071\n",
      "Name: error, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "# ==========================================\n",
    "# 1. ADVANCED FEATURE ENGINEERING (NO LEAKAGE)\n",
    "# ==========================================\n",
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Orchestrates the feature generation pipeline.\n",
    "    \"\"\"\n",
    "    print(\"--- 1. Text Processing (TF-IDF + SVD) ---\")\n",
    "    # TF-IDF captures \"addictive\", \"short\", \"boring\" - critical for playtime\n",
    "    # We limit to 5000 features, then compress to 64 dense features with SVD\n",
    "    tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "    # Fill NaN text\n",
    "    txt = df['text'].fillna('none').astype(str)\n",
    "    tfidf_matrix = tfidf.fit_transform(txt)\n",
    "    \n",
    "    print(\"   -> Compressing Text features via SVD...\")\n",
    "    svd = TruncatedSVD(n_components=64, random_state=42)\n",
    "    text_features = svd.fit_transform(tfidf_matrix)\n",
    "    \n",
    "    # DataFrame for text features\n",
    "    text_cols = [f'text_svd_{i}' for i in range(64)]\n",
    "    df_text = pd.DataFrame(text_features, columns=text_cols, index=df.index)\n",
    "    \n",
    "    # Concatenate original df with text features\n",
    "    df = pd.concat([df, df_text], axis=1)\n",
    "    \n",
    "    print(\"--- 2. Date Processing ---\")\n",
    "    if 'date' in df.columns:\n",
    "        dt = pd.to_datetime(df['date'], errors='coerce')\n",
    "        df['year'] = dt.dt.year.fillna(2015)\n",
    "        df['month'] = dt.dt.month.fillna(1)\n",
    "        # Days since a baseline (trends over time)\n",
    "        df['days_timeline'] = (dt - pd.Timestamp('2000-01-01')).dt.days.fillna(0)\n",
    "    else:\n",
    "        df['year'] = 2015\n",
    "        df['month'] = 1\n",
    "        df['days_timeline'] = 0\n",
    "\n",
    "    print(\"--- 3. Basic Counts ---\")\n",
    "    df['review_len'] = df['text'].fillna('').apply(len)\n",
    "    \n",
    "    return df, text_cols\n",
    "\n",
    "# ==========================================\n",
    "# 2. TARGET ENCODING (THE \"PEER\" TRICK)\n",
    "# ==========================================\n",
    "def add_target_stats(train_df, val_df, target_col='hours_transformed'):\n",
    "    \"\"\"\n",
    "    Computes User/Game mean hours on TRAIN ONLY and maps to Val.\n",
    "    This prevents data leakage which causes overfitting.\n",
    "    \"\"\"\n",
    "    print(\"--- 4. Computing Target Statistics (No Leakage) ---\")\n",
    "    \n",
    "    # Global Mean\n",
    "    global_mean = train_df[target_col].mean()\n",
    "    \n",
    "    # User Mean\n",
    "    user_means = train_df.groupby('userID')[target_col].mean()\n",
    "    train_df['user_target_enc'] = train_df['userID'].map(user_means)\n",
    "    val_df['user_target_enc'] = val_df['userID'].map(user_means)\n",
    "    \n",
    "    # Game Mean\n",
    "    game_means = train_df.groupby('gameID')[target_col].mean()\n",
    "    train_df['game_target_enc'] = train_df['gameID'].map(game_means)\n",
    "    val_df['game_target_enc'] = val_df['gameID'].map(game_means)\n",
    "    \n",
    "    # Fill NaNs (Cold Start) with Global Mean\n",
    "    for df_ in [train_df, val_df]:\n",
    "        df_['user_target_enc'] = df_['user_target_enc'].fillna(global_mean)\n",
    "        df_['game_target_enc'] = df_['game_target_enc'].fillna(global_mean)\n",
    "        \n",
    "    return train_df, val_df\n",
    "\n",
    "# ==========================================\n",
    "# 3. WIDE & DEEP MODEL ARCHITECTURE\n",
    "# ==========================================\n",
    "def build_wide_and_deep(n_users, n_items, n_dense):\n",
    "    \"\"\"\n",
    "    Wide & Deep Network.\n",
    "    - Deep Part: Embeddings (Captures Latent Factors)\n",
    "    - Wide Part: Text + Stats (Captures Explicit Signals)\n",
    "    \"\"\"\n",
    "    # --- Inputs ---\n",
    "    user_in = Input(shape=(1,), name='user_id')\n",
    "    item_in = Input(shape=(1,), name='item_id')\n",
    "    dense_in = Input(shape=(n_dense,), name='dense_features')\n",
    "    \n",
    "    # --- Embeddings (Latent) ---\n",
    "    # L2 Reg is crucial here. \n",
    "    emb_dim = 64\n",
    "    user_emb = Embedding(n_users, emb_dim, embeddings_regularizer=l2(1e-5), name='user_emb')(user_in)\n",
    "    item_emb = Embedding(n_items, emb_dim, embeddings_regularizer=l2(1e-5), name='item_emb')(item_in)\n",
    "    \n",
    "    u_vec = Flatten()(user_emb)\n",
    "    i_vec = Flatten()(item_emb)\n",
    "    \n",
    "    # --- Interaction (Dot Product) ---\n",
    "    # NCF usually works better if we explicitly calculate the dot product\n",
    "    # as a feature for the dense layer\n",
    "    dot = tf.keras.layers.Dot(axes=1)([u_vec, i_vec])\n",
    "    \n",
    "    # --- Concatenate Everything ---\n",
    "    # [UserVec, ItemVec, DotProduct, TextFeatures, StatsFeatures]\n",
    "    concat = Concatenate()([u_vec, i_vec, dot, dense_in])\n",
    "    \n",
    "    # --- MLP (The \"Brain\") ---\n",
    "    # Funnel structure: 512 -> 256 -> 128\n",
    "    x = Dense(512)(concat)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Dense(256)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(128)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # --- Output ---\n",
    "    output = Dense(1, activation='linear', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=[user_in, item_in, dense_in], outputs=output)\n",
    "    \n",
    "    # Optimizer: Nadam is often better for embeddings than Adam\n",
    "    model.compile(optimizer=Nadam(learning_rate=0.0005), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 3. PIPELINE ORCHESTRATION\n",
    "# ==========================================\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import datetime\n",
    "\n",
    "def readJSON(path):\n",
    "  for l in gzip.open(path, 'rt'):\n",
    "    d = eval(l)\n",
    "    u = d['userID']\n",
    "    try:\n",
    "      g = d['gameID']\n",
    "    except Exception as e:\n",
    "      g = None\n",
    "    yield u,g,d\n",
    "train_data = []\n",
    "user_games = defaultdict(list)\n",
    "game_users = defaultdict(list)\n",
    "\n",
    "for u,g,d in readJSON(\"train.json.gz\"):\n",
    "    user_games[u].append(g)\n",
    "    game_users[g].append(u)\n",
    "    train_data.append(d)\n",
    "\n",
    "df_train_data = pd.DataFrame(train_data)\n",
    "df_train_data.drop('user_id',axis=1,inplace=True)\n",
    "df_train_data['found_funny'] = df_train_data['found_funny'].fillna(0)\n",
    "df_train_data['compensation'] = df_train_data['compensation'].fillna(0)\n",
    "df_train_data.loc[df_train_data['compensation'] != 0,'compensation'] = 1\n",
    "df_test_hours_data = pd.read_csv(\"pairs_Hours.csv\")\n",
    "df_test_play_data = pd.read_csv(\"pairs_Played.csv\")\n",
    "\n",
    "# 2. Global Feature Engineering (Text, Date)\n",
    "df, text_cols = prepare_data(df)\n",
    "\n",
    "# 3. Encoding IDs\n",
    "user_enc = LabelEncoder()\n",
    "game_enc = LabelEncoder()\n",
    "df['user_idx'] = user_enc.fit_transform(df['userID'])\n",
    "df['game_idx'] = game_enc.fit_transform(df['gameID'])\n",
    "\n",
    "n_users = df['user_idx'].max() + 1\n",
    "n_items = df['game_idx'].max() + 1\n",
    "\n",
    "# 4. Strict Train/Val Split (Before Target Stats!)\n",
    "# This is critical. We cannot calculate user_mean on validation data.\n",
    "train_df, val_df = train_test_split(df, test_size=0.15, random_state=42)\n",
    "print(f\"Train size: {len(train_df)}, Val size: {len(val_df)}\")\n",
    "\n",
    "# 5. Add Target Statistics (Leakage-Free)\n",
    "train_df, val_df = add_target_stats(train_df, val_df)\n",
    "\n",
    "# 6. Prepare Dense Matrices\n",
    "# Features: Text SVD (64) + TargetStats (2) + ReviewLen (1) + Timeline (1)\n",
    "dense_cols = text_cols + ['user_target_enc', 'game_target_enc', 'review_len', 'days_timeline']\n",
    "\n",
    "# Scale numericals\n",
    "scaler = StandardScaler()\n",
    "X_train_dense = scaler.fit_transform(train_df[dense_cols])\n",
    "X_val_dense = scaler.transform(val_df[dense_cols])\n",
    "\n",
    "# 7. Inputs\n",
    "X_train = [train_df['user_idx'].values, train_df['game_idx'].values, X_train_dense]\n",
    "y_train = train_df['hours_transformed'].values\n",
    "\n",
    "X_val = [val_df['user_idx'].values, val_df['game_idx'].values, X_val_dense]\n",
    "y_val = val_df['hours_transformed'].values\n",
    "\n",
    "# 8. Build & Train\n",
    "model = build_wide_and_deep(n_users, n_items, len(dense_cols))\n",
    "model.summary()\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
    "\n",
    "print(\"\\nTraining Wide & Deep Model...\")\n",
    "# No sample weights this time. The Text features should naturally handle the outliers.\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=25,\n",
    "    batch_size=512, # Larger batch size for stable gradients\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 9. Evaluation\n",
    "print(\"\\n--- Evaluation ---\")\n",
    "val_preds = model.predict(X_val).flatten()\n",
    "val_preds = np.clip(val_preds, 0, None)\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_val - val_preds)**2))\n",
    "print(f\"FINAL RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Detailed Analysis\n",
    "val_df['pred'] = val_preds\n",
    "val_df['error'] = val_df['hours_transformed'] - val_df['pred']\n",
    "val_df['bin'] = pd.cut(val_df['hours_transformed'], bins=[0,2,4,6,8,10,20])\n",
    "print(\"\\nBias by Target Bin:\")\n",
    "print(val_df.groupby('bin', observed=False)['error'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3433587e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Passthrough Residual Pipeline...\n",
      "--- 1. Text Processing (TF-IDF + SVD) ---\n",
      "   -> Compressing Text features via SVD...\n",
      "--- 2. Date Processing ---\n",
      "--- 3. Basic Counts ---\n",
      "Train size: 157500, Val size: 17500\n",
      "--- 4. Computing Target Statistics (No Leakage) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_id             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_id             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_emb            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">858,880</span> │ user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_emb            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">311,936</span> │ item_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ item_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ passthrough_featur… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ flatten_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ scaled_features     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ dot_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ scaled_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ passthrough_feat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">200,192</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ wide_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │ passthrough_feat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ deep_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ wide_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ deep_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_id             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_id             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_emb            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │    \u001b[38;5;34m858,880\u001b[0m │ user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_emb            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │    \u001b[38;5;34m311,936\u001b[0m │ item_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ user_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ item_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ passthrough_featur… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_2 (\u001b[38;5;33mDot\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ flatten_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ flatten_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ scaled_features     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m390\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ dot_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ scaled_features[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ passthrough_feat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m200,192\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ wide_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m4\u001b[0m │ passthrough_feat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ deep_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ wide_output[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ deep_output[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,521,925</span> (5.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,521,925\u001b[0m (5.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,520,389</span> (5.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,520,389\u001b[0m (5.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Passthrough Residual Model...\n",
      "Epoch 1/30\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 58ms/step - loss: 27.7669 - mae: 3.2891 - val_loss: 5.0371 - val_mae: 1.7577 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - loss: 4.6682 - mae: 1.6688 - val_loss: 3.9983 - val_mae: 1.5768 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - loss: 4.1994 - mae: 1.5758 - val_loss: 3.7635 - val_mae: 1.5225 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 55ms/step - loss: 3.9272 - mae: 1.5224 - val_loss: 3.5865 - val_mae: 1.4715 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 55ms/step - loss: 3.6950 - mae: 1.4738 - val_loss: 3.8078 - val_mae: 1.5193 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - loss: 3.5401 - mae: 1.4398 - val_loss: 3.6243 - val_mae: 1.4759 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - loss: 3.2974 - mae: 1.3876 - val_loss: 4.0816 - val_mae: 1.5551 - learning_rate: 2.5000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - loss: 3.1865 - mae: 1.3618 - val_loss: 3.4881 - val_mae: 1.4349 - learning_rate: 2.5000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - loss: 3.0995 - mae: 1.3411 - val_loss: 3.7778 - val_mae: 1.4998 - learning_rate: 2.5000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - loss: 2.9713 - mae: 1.3111 - val_loss: 3.6927 - val_mae: 1.4857 - learning_rate: 2.5000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - loss: 2.7934 - mae: 1.2699 - val_loss: 4.1384 - val_mae: 1.5979 - learning_rate: 1.2500e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - loss: 2.7039 - mae: 1.2441 - val_loss: 3.7689 - val_mae: 1.5034 - learning_rate: 1.2500e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - loss: 2.5710 - mae: 1.2098 - val_loss: 3.8721 - val_mae: 1.5279 - learning_rate: 6.2500e-05\n",
      "\n",
      "--- Evaluation ---\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "FINAL RMSE: 1.8672\n",
      "\n",
      "Bias by Target Bin:\n",
      "bin\n",
      "(0, 2]     -1.944441\n",
      "(2, 4]     -0.817391\n",
      "(4, 6]      0.072973\n",
      "(6, 8]      1.092579\n",
      "(8, 10]     2.247772\n",
      "(10, 20]    3.767089\n",
      "Name: error, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout, BatchNormalization, Activation, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import gzip\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# ==========================================\n",
    "# 1. ADVANCED FEATURE ENGINEERING (NO LEAKAGE)\n",
    "# ==========================================\n",
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Orchestrates the feature generation pipeline.\n",
    "    \"\"\"\n",
    "    print(\"--- 1. Text Processing (TF-IDF + SVD) ---\")\n",
    "    # Increased to 8000/128 to capture maximum signal from text\n",
    "    tfidf = TfidfVectorizer(max_features=8000, stop_words='english', ngram_range=(1, 2))\n",
    "    # Fill NaN text\n",
    "    txt = df['text'].fillna('none').astype(str)\n",
    "    tfidf_matrix = tfidf.fit_transform(txt)\n",
    "    \n",
    "    print(\"   -> Compressing Text features via SVD...\")\n",
    "    svd = TruncatedSVD(n_components=128, random_state=42)\n",
    "    text_features = svd.fit_transform(tfidf_matrix)\n",
    "    \n",
    "    # DataFrame for text features\n",
    "    text_cols = [f'text_svd_{i}' for i in range(128)]\n",
    "    df_text = pd.DataFrame(text_features, columns=text_cols, index=df.index)\n",
    "    \n",
    "    # Concatenate original df with text features\n",
    "    df = pd.concat([df, df_text], axis=1)\n",
    "    \n",
    "    print(\"--- 2. Date Processing ---\")\n",
    "    if 'date' in df.columns:\n",
    "        dt = pd.to_datetime(df['date'], errors='coerce')\n",
    "        df['year'] = dt.dt.year.fillna(2015)\n",
    "        df['month'] = dt.dt.month.fillna(1)\n",
    "        # Days since a baseline (trends over time)\n",
    "        df['days_timeline'] = (dt - pd.Timestamp('2000-01-01')).dt.days.fillna(0)\n",
    "    else:\n",
    "        df['year'] = 2015\n",
    "        df['month'] = 1\n",
    "        df['days_timeline'] = 0\n",
    "\n",
    "    print(\"--- 3. Basic Counts ---\")\n",
    "    df['review_len'] = df['text'].fillna('').apply(len)\n",
    "    \n",
    "    return df, text_cols\n",
    "\n",
    "# ==========================================\n",
    "# 2. TARGET ENCODING (THE \"PEER\" TRICK)\n",
    "# ==========================================\n",
    "def add_target_stats(train_df, val_df, target_col='hours_transformed'):\n",
    "    \"\"\"\n",
    "    Computes User/Game mean hours on TRAIN ONLY and maps to Val.\n",
    "    Includes explicit interaction terms for the Wide Path.\n",
    "    \"\"\"\n",
    "    print(\"--- 4. Computing Target Statistics (No Leakage) ---\")\n",
    "    \n",
    "    # Global Mean\n",
    "    global_mean = train_df[target_col].mean()\n",
    "    \n",
    "    # User Mean\n",
    "    user_means = train_df.groupby('userID')[target_col].mean()\n",
    "    train_df['user_target_enc'] = train_df['userID'].map(user_means)\n",
    "    val_df['user_target_enc'] = val_df['userID'].map(user_means)\n",
    "    \n",
    "    # Game Mean\n",
    "    game_means = train_df.groupby('gameID')[target_col].mean()\n",
    "    train_df['game_target_enc'] = train_df['gameID'].map(game_means)\n",
    "    val_df['game_target_enc'] = val_df['gameID'].map(game_means)\n",
    "    \n",
    "    # Fill NaNs (Cold Start) with Global Mean\n",
    "    for df_ in [train_df, val_df]:\n",
    "        df_['user_target_enc'] = df_['user_target_enc'].fillna(global_mean)\n",
    "        df_['game_target_enc'] = df_['game_target_enc'].fillna(global_mean)\n",
    "        \n",
    "        # --- ACTIONABLE: Explicit Interaction Term ---\n",
    "        # If user is Hardcore (High Mean) AND Game is Long (High Mean) -> Result is Multiplicative\n",
    "        df_['interaction_mean'] = df_['user_target_enc'] * df_['game_target_enc']\n",
    "        \n",
    "    return train_df, val_df\n",
    "\n",
    "# ==========================================\n",
    "# 3. PASSTHROUGH RESIDUAL ARCHITECTURE\n",
    "# ==========================================\n",
    "def build_passthrough_model(n_users, n_items, n_scaled, n_passthrough):\n",
    "    \"\"\"\n",
    "    Architecture:\n",
    "    1. Passthrough Path (Wide): Raw Target Stats -> Dense(1)\n",
    "       * Guarantees baseline performance of simple averaging.\n",
    "       * NOT scaled, preserving the target magnitude.\n",
    "       \n",
    "    2. Deep Path: Embeddings + Scaled Features -> MLP\n",
    "       * Learns the *Residual* (Error) of the Passthrough path.\n",
    "    \"\"\"\n",
    "    # --- Inputs ---\n",
    "    user_in = Input(shape=(1,), name='user_id')\n",
    "    item_in = Input(shape=(1,), name='item_id')\n",
    "    scaled_in = Input(shape=(n_scaled,), name='scaled_features')\n",
    "    passthrough_in = Input(shape=(n_passthrough,), name='passthrough_features') # RAW features\n",
    "    \n",
    "    # ==========================\n",
    "    # PATH 1: PASSTHROUGH (WIDE)\n",
    "    # ==========================\n",
    "    # Direct Linear Connection. \n",
    "    # This layer essentially learns: Pred = w1*UserMean + w2*GameMean + w3*Interaction\n",
    "    # We initialize weights to 0.5 to encourage utilizing the signal immediately\n",
    "    wide_out = Dense(1, activation='linear', name='wide_output', \n",
    "                     kernel_initializer='ones')(passthrough_in)\n",
    "    \n",
    "    # ==========================\n",
    "    # PATH 2: DEEP RESIDUAL\n",
    "    # ==========================\n",
    "    \n",
    "    # --- Embeddings ---\n",
    "    # Increased dim to 128 to capture more latent factors\n",
    "    emb_dim = 128\n",
    "    user_emb = Embedding(n_users, emb_dim, embeddings_regularizer=l2(1e-6), name='user_emb')(user_in)\n",
    "    item_emb = Embedding(n_items, emb_dim, embeddings_regularizer=l2(1e-6), name='item_emb')(item_in)\n",
    "    \n",
    "    u_vec = Flatten()(user_emb)\n",
    "    i_vec = Flatten()(item_emb)\n",
    "    \n",
    "    # --- Interaction (Dot) ---\n",
    "    dot = tf.keras.layers.Dot(axes=1)([u_vec, i_vec])\n",
    "    \n",
    "    # --- Concatenate (Deep Input) ---\n",
    "    # We feed EVERYTHING into the Deep path too, so it has context\n",
    "    concat = Concatenate()([u_vec, i_vec, dot, scaled_in, passthrough_in])\n",
    "    \n",
    "    # --- MLP ---\n",
    "    x = Dense(512)(concat)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(256)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(64)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # Deep output learns the \"Correction\"\n",
    "    deep_out = Dense(1, activation='linear', name='deep_output')(x)\n",
    "    \n",
    "    # ==========================\n",
    "    # COMBINE\n",
    "    # ==========================\n",
    "    output = Add(name='final_output')([wide_out, deep_out])\n",
    "    \n",
    "    model = Model(inputs=[user_in, item_in, scaled_in, passthrough_in], outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=Nadam(learning_rate=0.0005), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 4. EXECUTION\n",
    "# ==========================================\n",
    "def readJSON(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        try:\n",
    "            g = d['gameID']\n",
    "        except Exception as e:\n",
    "            g = None\n",
    "        yield u, g, d\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Passthrough Residual Pipeline...\")\n",
    "    \n",
    "    # 1. Load\n",
    "    try:\n",
    "        train_data = []\n",
    "        user_games = defaultdict(list)\n",
    "        game_users = defaultdict(list)\n",
    "\n",
    "        for u, g, d in readJSON(\"train.json.gz\"):\n",
    "            user_games[u].append(g)\n",
    "            game_users[g].append(u)\n",
    "            train_data.append(d)\n",
    "\n",
    "        df_train_data = pd.DataFrame(train_data)\n",
    "        \n",
    "        if 'user_id' in df_train_data.columns:\n",
    "            df_train_data.drop('user_id', axis=1, inplace=True)\n",
    "            \n",
    "        df_train_data['found_funny'] = df_train_data['found_funny'].fillna(0)\n",
    "        df_train_data['compensation'] = df_train_data['compensation'].fillna(0)\n",
    "        df_train_data.loc[df_train_data['compensation'] != 0, 'compensation'] = 1\n",
    "        \n",
    "        df = df_train_data\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: train.json.gz not found. Creating dummy data...\")\n",
    "        df = pd.DataFrame({\n",
    "            'userID': ['u'+str(i%100) for i in range(10000)],\n",
    "            'gameID': ['g'+str(i%10) for i in range(10000)],\n",
    "            'hours_transformed': np.random.uniform(0, 14, 10000),\n",
    "            'text': ['game was addictive ' + str(i) for i in range(10000)],\n",
    "            'date': ['2020-01-01']*10000,\n",
    "            'found_funny': [0]*10000,\n",
    "            'compensation': [0]*10000\n",
    "        })\n",
    "\n",
    "    # 2. Global Feature Engineering\n",
    "    df, text_cols = prepare_data(df)\n",
    "    \n",
    "    # 3. Encoding IDs\n",
    "    user_enc = LabelEncoder()\n",
    "    game_enc = LabelEncoder()\n",
    "    df['user_idx'] = user_enc.fit_transform(df['userID'])\n",
    "    df['game_idx'] = game_enc.fit_transform(df['gameID'])\n",
    "    \n",
    "    n_users = df['user_idx'].max() + 1\n",
    "    n_items = df['game_idx'].max() + 1\n",
    "    \n",
    "    # 4. Strict Train/Val Split\n",
    "    train_df, val_df = train_test_split(df, test_size=0.10, random_state=42)\n",
    "    print(f\"Train size: {len(train_df)}, Val size: {len(val_df)}\")\n",
    "    \n",
    "    # 5. Add Target Statistics (Leakage-Free)\n",
    "    train_df, val_df = add_target_stats(train_df, val_df)\n",
    "    \n",
    "    # 6. Feature Groups\n",
    "    # Group A: Passthrough (Target Stats - DO NOT SCALE)\n",
    "    passthrough_cols = ['user_target_enc', 'game_target_enc', 'interaction_mean']\n",
    "    \n",
    "    # Group B: Scaled Features (Text, Dates, Counts)\n",
    "    scaled_cols = text_cols + ['review_len', 'days_timeline']\n",
    "    \n",
    "    # 7. Prepare Matrices\n",
    "    # Scale Group B only\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(train_df[scaled_cols])\n",
    "    X_val_scaled = scaler.transform(val_df[scaled_cols])\n",
    "    \n",
    "    # Passthrough Group A (Raw)\n",
    "    X_train_pass = train_df[passthrough_cols].values\n",
    "    X_val_pass = val_df[passthrough_cols].values\n",
    "    \n",
    "    # IDs\n",
    "    X_train = [train_df['user_idx'].values, train_df['game_idx'].values, X_train_scaled, X_train_pass]\n",
    "    y_train = train_df['hours_transformed'].values\n",
    "    \n",
    "    X_val = [val_df['user_idx'].values, val_df['game_idx'].values, X_val_scaled, X_val_pass]\n",
    "    y_val = val_df['hours_transformed'].values\n",
    "    \n",
    "    # 8. Build & Train\n",
    "    model = build_passthrough_model(n_users, n_items, len(scaled_cols), len(passthrough_cols))\n",
    "    model.summary()\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5)\n",
    "    \n",
    "    print(\"\\nTraining Passthrough Residual Model...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=30,\n",
    "        batch_size=512, \n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 9. Evaluation\n",
    "    print(\"\\n--- Evaluation ---\")\n",
    "    val_preds = model.predict(X_val).flatten()\n",
    "    val_preds = np.clip(val_preds, 0, None)\n",
    "    \n",
    "    rmse = np.sqrt(np.mean((y_val - val_preds)**2))\n",
    "    print(f\"FINAL RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    # Detailed Analysis\n",
    "    val_df['pred'] = val_preds\n",
    "    val_df['error'] = val_df['hours_transformed'] - val_df['pred']\n",
    "    val_df['bin'] = pd.cut(val_df['hours_transformed'], bins=[0,2,4,6,8,10,20])\n",
    "    print(\"\\nBias by Target Bin:\")\n",
    "    print(val_df.groupby('bin', observed=False)['error'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
