{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e1ec6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'SEC Link': '2025-11-14 08:00:15', 'Transaction Date': '2025-11-13', 'Ticker': 'PRMB', 'Company': 'Primo Brands Corp', 'Insider': 'Stanbrook Steven P', 'Position': 'Dir', 'Transaction Type': 'P - Purchase', 'Price': '$16.43', 'Shares Traded': '+54,540', 'Total Shares': '181,601', 'Ownership Change': '+43%', 'Value Change': '+$895,945'}, {'SEC Link': '2025-11-14 08:00:03', 'Transaction Date': '2025-11-12', 'Ticker': 'CATX', 'Company': 'Perspective Therapeutics, Inc.', 'Insider': 'Williamson Robert F III', 'Position': 'Dir', 'Transaction Type': 'P - Purchase', 'Price': '$2.10', 'Shares Traded': '+9,498', 'Total Shares': '118,846', 'Ownership Change': '+9%', 'Value Change': '+$19,946'}]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_rows = \"\"\"\n",
    "<tr style=\"background:#e7ffe7\"><td align=right></td><td align=right><div><a href=\"http://www.sec.gov/Archives/edgar/data/2042694/000149315225022578/xslF345X03/ownership.xml\" title=\"SEC Form 4\" target=\"_blank\">2025-11-14 08:00:15</a></div></td><td align=right><div>2025-11-13</div></td><td><b> <a href=\"/PRMB\" onmouseover=\"Tip('<img src=\\'https://www.profitspi.com/stock/stock-charts.ashx?chart=PRMB&v=stock-chart&vs=637453390322078326\\' alt=\\'\\' width=\\'360px\\' height=\\'280px\\'>', DELAY, 1)\" onmouseout=\"UnTip()\">PRMB</a></b></td><td><a href=\"/PRMB\">Primo Brands Corp</a></td><td><a href=\"/insider/Stanbrook-Steven-P/1219375\" title=\"181,601 direct shares\n",
    "1150 Assembly Drive, Suite 800\n",
    "Tampa, FL 33607\">Stanbrook Steven P</a></td><td>Dir</td><td>P - Purchase</td><td align=right>$16.43</td><td align=right>+54,540</td><td align=right>181,601</td><td align=right>+43%</td><td align=right>+$895,945</td><td align=right></td><td align=right></td><td align=right></td><td align=right></td></tr>\n",
    "<tr style=\"background:#f4fff4\"><td align=right></td><td align=right><div><a href=\"http://www.sec.gov/Archives/edgar/data/728387/000119312525281626/xslF345X03/ownership.xml\" title=\"SEC Form 4\" target=\"_blank\">2025-11-14 08:00:03</a></div></td><td align=right><div>2025-11-12</div></td><td><b> <a href=\"/CATX\" onmouseover=\"Tip('<img src=\\'https://www.profitspi.com/stock/stock-charts.ashx?chart=CATX&v=stock-chart&vs=637453390322078326\\' alt=\\'\\' width=\\'360px\\' height=\\'280px\\'>', DELAY, 1)\" onmouseout=\"UnTip()\">CATX</a></b></td><td><a href=\"/CATX\">Perspective Therapeutics, Inc.</a></td><td><a href=\"/insider/Williamson-Robert-F-III/1397331\" title=\"118,846 indirect shares\n",
    "C/O Perspective Therapeutics, Inc.\n",
    "2401 Elliott Avenue, Suite 320\n",
    "Seattle, WA 98121\">Williamson Robert F III</a></td><td>Dir</td><td>P - Purchase</td><td align=right>$2.10</td><td align=right>+9,498</td><td align=right>118,846</td><td align=right>+9%</td><td align=right>+$19,946</td><td align=right></td><td align=right></td><td align=right></td><td align=right></td></tr>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html_rows, 'html.parser')\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    sec_link = cols[1].find('a').text.strip()\n",
    "    transaction_date = cols[2].find('div').text.strip()\n",
    "    ticker = cols[3].find('a').text.strip()\n",
    "    company = cols[4].find('a').text.strip()\n",
    "    insider = cols[5].find('a').text.strip()\n",
    "    position = cols[6].text.strip()\n",
    "    transaction_type = cols[7].text.strip()\n",
    "    price = cols[8].text.strip()\n",
    "    shares_traded = cols[9].text.strip()\n",
    "    total_shares = cols[10].text.strip()\n",
    "    ownership_change = cols[11].text.strip()\n",
    "    value_change = cols[12].text.strip()\n",
    "\n",
    "    data.append({\n",
    "        'SEC Link': sec_link,\n",
    "        'Transaction Date': transaction_date,\n",
    "        'Ticker': ticker,\n",
    "        'Company': company,\n",
    "        'Insider': insider,\n",
    "        'Position': position,\n",
    "        'Transaction Type': transaction_type,\n",
    "        'Price': price,\n",
    "        'Shares Traded': shares_traded,\n",
    "        'Total Shares': total_shares,\n",
    "        'Ownership Change': ownership_change,\n",
    "        'Value Change': value_change\n",
    "    })\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb73a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@number(\"1\")\n",
    "    @partial_credit(2.0)\n",
    "    @visibility(\"after_due_date\")\n",
    "    def testQ1(self, set_score=None):\n",
    "        #report\n",
    "        set_score(2.0)\n",
    "\n",
    "    @number(\"2\")\n",
    "    @partial_credit(2.0)\n",
    "    @visibility(\"visible\")\n",
    "    def testQ2(self, set_score=None):\n",
    "        #time played prediction, public performance\n",
    "        x = MSE(self.y_hours, self.pred_hours)\n",
    "        score = 1\n",
    "        if x < 3.47272:\n",
    "            score = 1.5\n",
    "        if x < 3.06:\n",
    "            score = 2\n",
    "        set_score(score)\n",
    "\n",
    "    @number(\"3\")\n",
    "    @partial_credit(5.0)\n",
    "    @visibility(\"visible\")\n",
    "    def testQ3(self, set_score=None):\n",
    "        #time played prediction, absolute performance\n",
    "        x = MSE(self.y_hours, self.pred_hours, \"pri\")\n",
    "        score = 1\n",
    "        if x < 4.90195:\n",
    "            score = 2\n",
    "        if x < 3.35149:\n",
    "            score = 2.5\n",
    "        if x < 3.3:\n",
    "            score = 3.5\n",
    "        if x < 3.02:\n",
    "            score = 4.0\n",
    "        if x < 3.01:\n",
    "            score = 4.5\n",
    "        if x < 3.003:\n",
    "            score = 5\n",
    "        set_score(score)\n",
    "\n",
    "    @number(\"4\")\n",
    "    @partial_credit(3.0)\n",
    "    @visibility(\"visible\")\n",
    "    def testQ4(self, set_score=None):\n",
    "        #time played prediction, ranking, 258\n",
    "        x = MSE(self.y_hours, self.pred_hours, \"pri\")\n",
    "        score = 1\n",
    "        if x <= 3.020979966238632:\n",
    "            score = 1.5\n",
    "        if x <= 3.013583039937545:\n",
    "            score = 2\n",
    "        if x <= 3.010529845519971:\n",
    "            score = 2.5\n",
    "        if x <= 3.007931984528765:\n",
    "            score = 3\n",
    "        set_score(score)\n",
    "\n",
    "    @number(\"5\")\n",
    "    @partial_credit(2.0)\n",
    "    @visibility(\"visible\")\n",
    "    def testQ5(self, set_score=None):\n",
    "        #would play prediction, public performance\n",
    "        x = acc(self.y_played, self.pred_played)\n",
    "        score = 1\n",
    "        if x > 0.70370:\n",
    "            score = 1.5\n",
    "        if x > 0.71:\n",
    "            score = 2\n",
    "        set_score(score)\n",
    "\n",
    "    @number(\"6\")\n",
    "    @partial_credit(5.0)\n",
    "    @visibility(\"visible\")\n",
    "    def testQ6(self, set_score=None):\n",
    "        #would play prediction, absolute performance\n",
    "        x = acc(self.y_played, self.pred_played, \"pri\")\n",
    "        score = 1\n",
    "        if x > 0.68630:\n",
    "            score = 2\n",
    "        if x > 0.7034:\n",
    "            score = 2.5\n",
    "        if x > 0.705:\n",
    "            score = 3\n",
    "        if x > 0.71:\n",
    "            score = 4\n",
    "        if x > 0.714:\n",
    "            score = 5\n",
    "        set_score(score)\n",
    "\n",
    "\n",
    "    @number(\"7\")\n",
    "    @partial_credit(3.0)\n",
    "    @visibility(\"visible\")\n",
    "    def testQ7(self, set_score=None):\n",
    "        #would play prediction, ranking, 258\n",
    "        x = acc(self.y_played, self.pred_played, \"pri\")\n",
    "        score = 1\n",
    "        if x >= 0.7099:\n",
    "            score = 1.5\n",
    "        if x >= 0.7191:\n",
    "            score = 2\n",
    "        if x >= 0.7283:\n",
    "            score = 2.5\n",
    "        if x >= 0.7371:\n",
    "            score = 3\n",
    "        set_score(score)\n",
    "\"\"\"\n",
    "\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "\n",
    "def readJSON(path):\n",
    "  for l in gzip.open(path, 'rt'):\n",
    "    d = eval(l)\n",
    "    u = d['userID']\n",
    "    try:\n",
    "      g = d['gameID']\n",
    "    except Exception as e:\n",
    "      g = None\n",
    "    yield u,g,d\n",
    "\n",
    "### Time-played baseline: compute averages for each user, or return the global average if we've never seen the user before\n",
    "\n",
    "allHours = []\n",
    "userHours = defaultdict(list)\n",
    "\n",
    "for user,game,d in readJSON(\"train.json.gz\"):\n",
    "  h = d['hours_transformed']\n",
    "  allHours.append(h)\n",
    "  userHours[user].append(h)\n",
    "\n",
    "globalAverage = sum(allHours) / len(allHours)\n",
    "userAverage = {}\n",
    "for u in userHours:\n",
    "  userAverage[u] = sum(userHours[u]) / len(userHours[u])\n",
    "\n",
    "predictions = open(\"predictions_Hours.csv\", 'w')\n",
    "for l in open(\"pairs_Hours.csv\"):\n",
    "  if l.startswith(\"userID\"):\n",
    "    #header\n",
    "    predictions.write(l)\n",
    "    continue\n",
    "  u,g = l.strip().split(',')\n",
    "  if u in userAverage:\n",
    "    predictions.write(u + ',' + g + ',' + str(userAverage[u]) + '\\n')\n",
    "  else:\n",
    "    predictions.write(u + ',' + g + ',' + str(globalAverage) + '\\n')\n",
    "\n",
    "predictions.close()\n",
    "\n",
    "### Would-play baseline: just rank which games are popular and which are not, and return '1' if a game is among the top-ranked\n",
    "\n",
    "gameCount = defaultdict(int)\n",
    "totalPlayed = 0\n",
    "\n",
    "for user,game,_ in readJSON(\"train.json.gz\"):\n",
    "  gameCount[game] += 1\n",
    "  totalPlayed += 1\n",
    "\n",
    "mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > totalPlayed/2: break\n",
    "\n",
    "predictions = open(\"predictions_Played.csv\", 'w')\n",
    "for l in open(\"pairs_Played.csv\"):\n",
    "  if l.startswith(\"userID\"):\n",
    "    #header\n",
    "    predictions.write(l)\n",
    "    continue\n",
    "  u,g = l.strip().split(',')\n",
    "  if g in return1:\n",
    "    predictions.write(u + ',' + g + \",1\\n\")\n",
    "  else:\n",
    "    predictions.write(u + ',' + g + \",0\\n\")\n",
    "\n",
    "predictions.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d28d6368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEC Link</th>\n",
       "      <th>Transaction Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Company</th>\n",
       "      <th>Insider</th>\n",
       "      <th>Position</th>\n",
       "      <th>Transaction Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Shares Traded</th>\n",
       "      <th>Total Shares</th>\n",
       "      <th>Ownership Change</th>\n",
       "      <th>Value Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-14 08:00:15</td>\n",
       "      <td>2025-11-13</td>\n",
       "      <td>PRMB</td>\n",
       "      <td>Primo Brands Corp</td>\n",
       "      <td>Stanbrook Steven P</td>\n",
       "      <td>Dir</td>\n",
       "      <td>P - Purchase</td>\n",
       "      <td>$16.43</td>\n",
       "      <td>+54,540</td>\n",
       "      <td>181,601</td>\n",
       "      <td>+43%</td>\n",
       "      <td>+$895,945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-14 08:00:03</td>\n",
       "      <td>2025-11-12</td>\n",
       "      <td>CATX</td>\n",
       "      <td>Perspective Therapeutics, Inc.</td>\n",
       "      <td>Williamson Robert F III</td>\n",
       "      <td>Dir</td>\n",
       "      <td>P - Purchase</td>\n",
       "      <td>$2.10</td>\n",
       "      <td>+9,498</td>\n",
       "      <td>118,846</td>\n",
       "      <td>+9%</td>\n",
       "      <td>+$19,946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SEC Link Transaction Date Ticker  \\\n",
       "0  2025-11-14 08:00:15       2025-11-13   PRMB   \n",
       "1  2025-11-14 08:00:03       2025-11-12   CATX   \n",
       "\n",
       "                          Company                  Insider Position  \\\n",
       "0               Primo Brands Corp       Stanbrook Steven P      Dir   \n",
       "1  Perspective Therapeutics, Inc.  Williamson Robert F III      Dir   \n",
       "\n",
       "  Transaction Type   Price Shares Traded Total Shares Ownership Change  \\\n",
       "0     P - Purchase  $16.43       +54,540      181,601             +43%   \n",
       "1     P - Purchase   $2.10        +9,498      118,846              +9%   \n",
       "\n",
       "  Value Change  \n",
       "0    +$895,945  \n",
       "1     +$19,946  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b04aedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the HTML file\n",
    "with open('/home/scotty/dsc_256/fall_25/assignment_02/raw_data/output.html', 'r', encoding='utf-8') as file:\n",
    "    html_rows = file.read()\n",
    "\n",
    "soup = BeautifulSoup(html_rows, 'html.parser')\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "data = []\n",
    "for row in rows[576:600]:\n",
    "    cols = row.find_all('td')\n",
    "    sec_link = cols[1].find('a').text.strip()\n",
    "    transaction_date = cols[2].find('div').text.strip()\n",
    "    ticker = cols[3].find('a').text.strip()\n",
    "    company = cols[4].find('a').text.strip()\n",
    "    insider = cols[5].find('a').text.strip()\n",
    "    position = cols[6].text.strip()\n",
    "    transaction_type = cols[7].text.strip()\n",
    "    price = cols[8].text.strip()\n",
    "    shares_traded = cols[9].text.strip()\n",
    "    total_shares = cols[10].text.strip()\n",
    "    ownership_change = cols[11].text.strip()\n",
    "    value_change = cols[12].text.strip()\n",
    "\n",
    "    data.append({\n",
    "        'SEC Link': sec_link,\n",
    "        'Transaction Date': transaction_date,\n",
    "        'Ticker': ticker,\n",
    "        'Company': company,\n",
    "        'Insider': insider,\n",
    "        'Position': position,\n",
    "        'Transaction Type': transaction_type,\n",
    "        'Price': price,\n",
    "        'Shares Traded': shares_traded,\n",
    "        'Total Shares': total_shares,\n",
    "        'Ownership Change': ownership_change,\n",
    "        'Value Change': value_change\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06916363",
   "metadata": {},
   "source": [
    "pseudocode for forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f5f903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=0, step=1)\n"
     ]
    }
   ],
   "source": [
    "def forward(user_idx, item_idx, target_stage):\n",
    "    # 1. Get embeddings\n",
    "    u_emb = user_embedding(user_idx)\n",
    "    i_emb = item_embedding(item_idx)\n",
    "    \n",
    "    # 2. Calculate Raw Intentions (delta) for ALL stages\n",
    "    # This is the Tensor Decomposition part: <gamma_l, gamma_i * gamma_u>\n",
    "    # We compute this for k = 1 to L\n",
    "    intentions = []\n",
    "    for k in range(1, L + 1):\n",
    "        stage_emb = stage_embedding(k)\n",
    "        # Element-wise product of User and Item, dot product with Stage\n",
    "        delta_k = torch.sum(stage_emb * (u_emb * i_emb), dim=1) \n",
    "        intentions.append(softplus(delta_k))\n",
    "    \n",
    "    # 3. Summation for Monotonicity\n",
    "    # Score for target_stage = sum(intentions from target_stage to L)\n",
    "    score = sum(intentions[target_stage-1:]) \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ChainRecModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_stages, K=16):\n",
    "        super(ChainRecModel, self).__init__()\n",
    "        self.L = num_stages # L = 4 for your new chain\n",
    "        self.K = K\n",
    "        \n",
    "        # 1. Embeddings (Learned Parameters)\n",
    "        self.user_emb = nn.Embedding(num_users, K)\n",
    "        self.item_emb = nn.Embedding(num_items, K)\n",
    "        self.stage_emb = nn.Embedding(num_stages + 1, K) # +1 for 1-based indexing\n",
    "        \n",
    "        # 2. Biases\n",
    "        self.b_u = nn.Embedding(num_users, 1)\n",
    "        self.b_i = nn.Embedding(num_items, 1)\n",
    "        self.b_0 = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        # 3. Softplus Parameter (Learned Parameter Beta)\n",
    "        # Beta is initialized >= 1 and learned automatically \n",
    "        # We model log(beta) for guaranteed positivity\n",
    "        self.log_beta = nn.Parameter(torch.tensor(0.0)) # Initializes beta to exp(0) = 1.0\n",
    "\n",
    "        # Initialize weights (e.g., Xavier uniform)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        # Good practice for MF/Recommendation models\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.item_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.stage_emb.weight)\n",
    "        # Biases often initialized to zero\n",
    "        nn.init.zeros_(self.b_u.weight)\n",
    "        nn.init.zeros_(self.b_i.weight)\n",
    "\n",
    "    def softplus_rectifier(self, delta):\n",
    "        # Implements: delta+ = (1/beta) * log(1 + exp(beta * delta)) \n",
    "        beta = torch.exp(self.log_beta) # Ensure beta >= 1\n",
    "        return (1 / beta) * torch.log(1 + torch.exp(beta * delta))\n",
    "\n",
    "    def forward(self, u_indices, i_indices):\n",
    "        \"\"\"\n",
    "        Calculates the preference score s_ui,l for all stages l=1 to L.\n",
    "        u_indices, i_indices: Batches of user and item IDs (long tensor)\n",
    "        \"\"\"\n",
    "        # Get embeddings and biases for the batch\n",
    "        u_vec = self.user_emb(u_indices)\n",
    "        i_vec = self.item_emb(i_indices)\n",
    "        \n",
    "        b_u = self.b_u(u_indices).squeeze()\n",
    "        b_i = self.b_i(i_indices).squeeze()\n",
    "        b_0 = self.b_0.expand_as(b_u)\n",
    "        \n",
    "        # Array to hold the preference scores for all stages: [batch_size, L]\n",
    "        s_scores = torch.zeros(u_vec.shape[0], self.L, device=u_vec.device)\n",
    "        \n",
    "        # 1. Calculate and Rectify Intentions (delta+)\n",
    "        activated_intentions = []\n",
    "        for l in range(1, self.L + 1):\n",
    "            # Stage embedding (gamma_l)\n",
    "            l_vec = self.stage_emb(torch.tensor(l, device=u_vec.device))\n",
    "            \n",
    "            # Intention score (delta_ui,l): <gamma_l, gamma_i o gamma_u> [cite: 310]\n",
    "            # l_vec is 1xK, u_vec, i_vec are BxK\n",
    "            delta_ui_l = torch.sum(l_vec * (u_vec * i_vec), dim=1) \n",
    "            \n",
    "            # Rectify intention (delta_ui,l+)\n",
    "            delta_plus = self.softplus_rectifier(delta_ui_l)\n",
    "            activated_intentions.append(delta_plus)\n",
    "        \n",
    "        # 2. Calculate Monotonic Preference Scores (s_ui,l)\n",
    "        # s_ui,l is the sum of intentions from stage l to L [cite: 335]\n",
    "        for l in range(1, self.L + 1):\n",
    "            # Sum of intentions from l to L\n",
    "            sum_of_intentions = sum(activated_intentions[l-1:])\n",
    "            \n",
    "            # Final score: Biases + Sum(delta+) [cite: 335]\n",
    "            s_ui_l = b_0 + b_u + b_i + sum_of_intentions\n",
    "            s_scores[:, l-1] = s_ui_l\n",
    "            \n",
    "        # The result is s_scores (B x L), where s_scores[:, l-1] is s_ui,l\n",
    "        # The output naturally preserves monotonicity: s_ui,1 >= s_ui,2 >= ...\n",
    "        return s_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_opt_loss(model, pos_u, pos_i, l_stars, neg_u, neg_i, c_weights=1.0):\n",
    "    # 1. Get monotonic scores s_ui,l for positive and negative samples\n",
    "    pos_s = model(pos_u, pos_i) # B x L\n",
    "    neg_s = model(neg_u, neg_i) # B*N x L (B=batch size, N=negatives per positive)\n",
    "\n",
    "    # 2. Extract Activated Intentions (delta_plus) - need to re-implement the internal logic\n",
    "    # Note: For efficiency, you might want the forward pass to return delta_plus array directly.\n",
    "    # Assuming delta_plus can be accessed/recomputed for simplicity here:\n",
    "    \n",
    "    # 3. Positive Loss: Maximize log(p_ui, l*) for the positive samples\n",
    "    positive_loss = 0\n",
    "    for idx, l_star in enumerate(l_stars):\n",
    "        # l_star is 1-indexed, Python array is 0-indexed.\n",
    "        # Ensure delta_plus is calculated for l_star (must be re-extracted)\n",
    "        \n",
    "        # This part requires re-running the intention calculation specific to l_star\n",
    "        # The key probability is p_ui, l* = 1 - exp(-delta_ui, l*+)\n",
    "        \n",
    "        # Placeholder for delta_plus at l_star. In real code, compute this:\n",
    "        delta_plus_l_star = model.softplus_rectifier(model.get_intention_delta(pos_u[idx], pos_i[idx], l_star)) \n",
    "        \n",
    "        p_l_star = 1 - torch.exp(-delta_plus_l_star)\n",
    "        positive_loss += torch.log(p_l_star)\n",
    "    \n",
    "    # 4. Negative Loss: Minimize P(Purchase) (1 - p_ui, l*+1) for the negative samples\n",
    "    # For a sampled negative i', its edge l* is 0 (no interaction). The loss edge is l*+1 = 1 (Purchase).\n",
    "    \n",
    "    # Get the score for Purchase stage (l=1), which is neg_s[:, 0]\n",
    "    s_neg_purchase = neg_s[:, 0] \n",
    "    \n",
    "    # P(Purchase) = sigma(s_neg_purchase)\n",
    "    p_neg_purchase = torch.sigmoid(s_neg_purchase)\n",
    "\n",
    "    # The negative term is log(1 - P(Purchase))\n",
    "    negative_loss = c_weights * torch.log(1 - p_neg_purchase).sum()\n",
    "    \n",
    "    # We ignore the PMI term p_ui,cap for negatives as it is often approximated by 1 for l*=0.\n",
    "    \n",
    "    # Total loss to MINIMIZE (negative of the objective function)\n",
    "    # The negative sign is applied because the objective maximizes the log-likelihood\n",
    "    total_loss = - (positive_loss.sum() + negative_loss) \n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f20501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# Assume ChainRecModel and edge_opt_loss are defined\n",
    "\n",
    "# --- Setup ---\n",
    "model = ChainRecModel(num_users, num_items, num_stages, K=16)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005) # Learning rate is selected from {0.001, 0.005, 0.01, ...} [cite: 389]\n",
    "num_negatives = 4 # Common setting is N=1, but N>1 is possible (e.g., N=4 or more)\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    # Use your custom DataLoader/Sampler that yields (u, i, l_star)\n",
    "    for pos_u_batch, pos_i_batch, l_stars_batch in training_data_loader:\n",
    "        \n",
    "        # 1. Generate Negative Samples for the batch\n",
    "        neg_u_list, neg_i_list = [], []\n",
    "        \n",
    "        for u_idx in pos_u_batch:\n",
    "            # Generate N negative items for this user (must not be in I_u_plus)\n",
    "            neg_items = sample_negatives(u_idx, num_negatives, item_pool, interaction_history)\n",
    "            neg_u_list.extend([u_idx] * num_negatives)\n",
    "            neg_i_list.extend(neg_items)\n",
    "\n",
    "        # Convert to Tensors\n",
    "        neg_u_tensor = torch.tensor(neg_u_list, dtype=torch.long)\n",
    "        neg_i_tensor = torch.tensor(neg_i_list, dtype=torch.long)\n",
    "        \n",
    "        # Determine c_weights based on scheme (Stage 2.1)\n",
    "        c_weights = calculate_stagewise_weights(l_stars_batch) # c_weights=1.0 for Uniform\n",
    "\n",
    "        # 2. Calculate Loss (EdgeOpt)\n",
    "        optimizer.zero_grad()\n",
    "        loss = edge_opt_loss(model, \n",
    "                             pos_u_batch, pos_i_batch, l_stars_batch, \n",
    "                             neg_u_tensor, neg_i_tensor, \n",
    "                             c_weights=c_weights)\n",
    "\n",
    "        # 3. Optimization (ADAM)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    # Validation check after each epoch\n",
    "    # We track the cross-entropy loss for the last stage (L) on a validation set and stop if it doesn't decrease[cite: 387].\n",
    "    validation_performance = evaluate(model, validation_set)\n",
    "    if validation_performance is not improving:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1063a9",
   "metadata": {},
   "source": [
    "# ðŸ“ Project Summary: Item Recommendation on Monotonic Behavior Chains\n",
    "\n",
    "This document summarizes our conceptualization and architectural design for implementing the $\\text{chainRec}$ framework on the Steam dataset, based on the paper *Item Recommendation on Monotonic Behavior Chains* (RecSys '18).\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— The Monotonic Behavior Chain\n",
    "\n",
    "The core principle is that user interactions follow a monotonic sequence, where a stronger (more explicit) signal implies all weaker (more implicit) signals.\n",
    "\n",
    "### Defined 4-Stage Chain ($L=4$)\n",
    "We extend the chain to four stages by incorporating **sentiment analysis** on the review text, creating the strongest signal in the chain:\n",
    "\n",
    "| Stage ($l$) | Interaction Type | Condition ($y_{ui,l}=1$) | Sparsity |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| **1** | **Purchase** | Item is in the training data (record exists). | Densest |\n",
    "| **2** | **Play** | `hours` $\\ge 1.0$ (Example Threshold). | Moderate |\n",
    "| **3** | **Review** | `text` is not empty. | Sparse |\n",
    "| **4** | **Recommend** | `text` is not empty **AND** Sentiment Score $\\ge 0.7$ (Positive). | Sparsest |\n",
    "\n",
    "The $l_{ui}^{*}$ variable represents the **last observed stage** (the \"edge\") for a user-item pair.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Model Architecture: Monotonic Scoring Function\n",
    "\n",
    "The $\\text{chainRec}$ model uses a tensor factorization format combined with a summation mechanism to intrinsically enforce monotonicity in the predicted scores ($s_{ui,1} \\ge s_{ui,2} \\ge \\dots \\ge s_{ui,L}$).\n",
    "\n",
    "### Behavioral Intention ($\\delta_{ui,l}^{+}$)\n",
    "Raw intention scores $\\delta_{ui,l} = \\langle \\gamma_l, \\gamma_i \\circ \\gamma_u \\rangle$ are passed through a learned parametric rectifier:\n",
    "$$\\delta_{ui,l}^{+} = \\frac{1}{\\beta} \\log(1 + \\exp(\\beta\\delta_{ui,l}))$$\n",
    "This rectifier ensures non-negativity ($\\delta_{ui,l}^{+} \\ge 0$).\n",
    "\n",
    "### Monotonic Preference Score ($s_{ui,l}$)\n",
    "The preference score for stage $l$ is the sum of activated intentions from $l$ to $L$:\n",
    "$$s_{ui,l} = b_0 + b_i + b_u + \\sum_{k=l}^{L} \\delta_{ui,k}^{+}$$\n",
    "A strong intention to **Recommend** ($\\delta_{ui,4}^{+}$) automatically contributes to the score for **Review** ($s_{ui,3}$), **Play** ($s_{ui,2}$), and **Purchase** ($s_{ui,1}$).\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Optimization: EdgeOpt Loss and Sampling\n",
    "\n",
    "The model is optimized using **ADAM** and the $\\text{EdgeOpt}$ criterion, which focuses on maximizing the joint probability of stopping exactly at $l_{ui}^{*}$.\n",
    "\n",
    "### The Loss Objective ($\\text{EdgeOpt}$)\n",
    "The training objective is based on maximizing the rebalanced log-likelihood (Eq. 16).\n",
    "\n",
    "$$\\mathcal{L} \\approx \\sum_{u} \\left( \\sum_{i \\in I_u^{+}} \\log p_{ui,l^{*}} + \\sum_{i' \\in \\tilde{I}_{u}} c_{ui', l_{ui'}^{*}} \\left( \\log(1-P(y_{ui', 1}=1)) + \\log p_{ui', \\cap} \\right) \\right)$$\n",
    "\n",
    "### Sampling Schemes Differentiation\n",
    "Both schemes sample unobserved items $i'$ (where $l_{ui'}^{*}=0$):\n",
    "\n",
    "| Scheme | Description | Loss Weight $c$ |\n",
    "| :--- | :--- | :---------------------------------- |\n",
    "| **Uniform** | Negative items are sampled uniformly, regardless of stage density. | $c_{ui'} = 1$ |\n",
    "| **Stagewise** | Negative item loss is weighted based on the sparsity of the associated positive edge $l_{ui}^{*}$. | $c_{ui, l^*} \\propto$ x (Density ratio) |\n",
    "\n",
    "$$x=\\frac{|I_{u,l^*+1}^{-}|}{|I_{u,l^*}^{+}|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc8773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Utility Functions (Placeholders for real-world NLP/Data Prep) ---\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"\n",
    "    Placeholder: Loads Steam data and calculates the edge l_star for each positive interaction.\n",
    "    Returns: \n",
    "        - list of (user_id, item_id, l_star) for training\n",
    "        - dict: user_id -> set of positive item_ids (I_u_plus)\n",
    "        - int: num_users, num_items\n",
    "    \"\"\"\n",
    "    # --- Simplified Mock Data based on 4-stage chain ---\n",
    "    MOCK_EDGES = [\n",
    "        # (u, i, l*)\n",
    "        (0, 100, 4),  # Reviewed and Recommended (l*=4)\n",
    "        (0, 101, 3),  # Reviewed, not Recommended (l*=3)\n",
    "        (0, 102, 2),  # Played, not Reviewed (l*=2)\n",
    "        (1, 100, 1),  # Purchased, not Played (l*=1)\n",
    "        (1, 103, 4),  # Reviewed and Recommended (l*=4)\n",
    "        (2, 104, 2),\n",
    "    ]\n",
    "    \n",
    "    train_data = MOCK_EDGES\n",
    "    num_users = 3\n",
    "    num_items = 105 \n",
    "    \n",
    "    # Build Interaction History\n",
    "    interaction_history = defaultdict(set)\n",
    "    for u, i, _ in train_data:\n",
    "        interaction_history[u].add(i)\n",
    "\n",
    "    return train_data, interaction_history, num_users, num_items\n",
    "\n",
    "def calculate_stagewise_weights(train_data, num_stages):\n",
    "    \"\"\"\n",
    "    Placeholder: Calculates the constant weights c_l* for Stagewise Sampling.\n",
    "    Requires complex pre-analysis of the dataset density.\n",
    "    Returns: A dictionary {l_star: weight}\n",
    "    \"\"\"\n",
    "    # In practice, rare stages get higher weights.\n",
    "    # Stage 4 (Recommend) is the rarest, so it gets the highest weight.\n",
    "    weights = {}\n",
    "    for l in range(1, num_stages + 1):\n",
    "        # Mock weights: scale inversely with stage density\n",
    "        weights[l] = 1.0 + (num_stages - l) * 2.0\n",
    "        \n",
    "    return weights\n",
    "\n",
    "# --- A. The Data Sampler/DataLoader Implementation ---\n",
    "\n",
    "class EdgeDataset(Dataset):\n",
    "    \"\"\"Dataset storing all positive (u, i, l*) edges for ChainRec.\"\"\"\n",
    "    def __init__(self, edges):\n",
    "        self.edges = edges\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.edges)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        u, i, l_star = self.edges[idx]\n",
    "        return torch.tensor(u, dtype=torch.long), \\\n",
    "               torch.tensor(i, dtype=torch.long), \\\n",
    "               torch.tensor(l_star, dtype=torch.long)\n",
    "\n",
    "def sample_negatives(u_idx, num_negatives, num_items, interaction_history):\n",
    "    \"\"\"Samples N items that user u_idx has NOT interacted with.\"\"\"\n",
    "    u_pos_items = interaction_history[u_idx.item()]\n",
    "    \n",
    "    neg_items = []\n",
    "    while len(neg_items) < num_negatives:\n",
    "        neg_i = random.randint(0, num_items - 1)\n",
    "        if neg_i not in u_pos_items:\n",
    "            neg_items.append(neg_i)\n",
    "    return neg_items\n",
    "\n",
    "def chainrec_collate_fn(batch, num_items, interaction_history, num_negatives, stagewise_weights, use_stagewise=False):\n",
    "    \"\"\"\n",
    "    Custom collate function to perform in-batch negative sampling.\n",
    "    \"\"\"\n",
    "    pos_u_batch, pos_i_batch, l_stars_batch = [i.tolist() for i in zip(*batch)]\n",
    "\n",
    "    neg_u_list, neg_i_list, c_weights_list = [], [], []\n",
    "\n",
    "    for u_idx, l_star in zip(pos_u_batch, l_stars_batch):\n",
    "        # 1. Sample N negatives per positive example\n",
    "        neg_items = sample_negatives(torch.tensor(u_idx), num_negatives, num_items, interaction_history)\n",
    "        \n",
    "        neg_u_list.extend([u_idx] * num_negatives)\n",
    "        neg_i_list.extend(neg_items)\n",
    "        \n",
    "        # 2. Stagewise Weighting (c_weights)\n",
    "        if use_stagewise:\n",
    "            # All N negatives corresponding to this l_star get the same weight\n",
    "            c_weight = stagewise_weights.get(l_star, 1.0)\n",
    "            c_weights_list.extend([c_weight] * num_negatives)\n",
    "        else:\n",
    "            c_weights_list.extend([1.0] * num_negatives) # Uniform: c=1\n",
    "\n",
    "    return torch.tensor(pos_u_batch, dtype=torch.long), \\\n",
    "           torch.tensor(pos_i_batch, dtype=torch.long), \\\n",
    "           torch.tensor(l_stars_batch, dtype=torch.long), \\\n",
    "           torch.tensor(neg_u_list, dtype=torch.long), \\\n",
    "           torch.tensor(neg_i_list, dtype=torch.long), \\\n",
    "           torch.tensor(c_weights_list, dtype=torch.float)\n",
    "\n",
    "# --- Model Definition (re-used from conversation) ---\n",
    "\n",
    "class ChainRecModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_stages, K=16):\n",
    "        super(ChainRecModel, self).__init__()\n",
    "        self.L = num_stages\n",
    "        self.K = K\n",
    "        self.user_emb = nn.Embedding(num_users, K)\n",
    "        self.item_emb = nn.Embedding(num_items, K)\n",
    "        self.stage_emb = nn.Embedding(num_stages + 1, K) \n",
    "        self.b_u = nn.Embedding(num_users, 1)\n",
    "        self.b_i = nn.Embedding(num_items, 1)\n",
    "        self.b_0 = nn.Parameter(torch.zeros(1))\n",
    "        self.log_beta = nn.Parameter(torch.tensor(0.0))\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        # Initialization logic (Xavier)\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.item_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.stage_emb.weight)\n",
    "        nn.init.zeros_(self.b_u.weight)\n",
    "        nn.init.zeros_(self.b_i.weight)\n",
    "\n",
    "    def softplus_rectifier(self, delta):\n",
    "        # delta+ = (1/beta) * log(1 + exp(beta * delta))\n",
    "        beta = torch.exp(self.log_beta)\n",
    "        return (1 / beta) * torch.log(1 + torch.exp(beta * delta))\n",
    "    \n",
    "    def get_intention_deltas(self, u_indices, i_indices):\n",
    "        \"\"\"Calculates and returns all L activated intentions (delta+).\"\"\"\n",
    "        u_vec = self.user_emb(u_indices)\n",
    "        i_vec = self.item_emb(i_indices)\n",
    "        \n",
    "        activated_intentions = []\n",
    "        for l in range(1, self.L + 1):\n",
    "            l_vec = self.stage_emb(torch.tensor(l, device=u_vec.device))\n",
    "            # delta_ui,l: <gamma_l, gamma_i o gamma_u>\n",
    "            delta_ui_l = torch.sum(l_vec * (u_vec * i_vec), dim=1) \n",
    "            delta_plus = self.softplus_rectifier(delta_ui_l)\n",
    "            activated_intentions.append(delta_plus)\n",
    "        return activated_intentions\n",
    "\n",
    "    def forward(self, u_indices, i_indices):\n",
    "        \"\"\"Calculates the preference score s_ui,l for all stages l=1 to L.\"\"\"\n",
    "        u_vec, i_vec = self.user_emb(u_indices), self.item_emb(i_indices)\n",
    "        b_u, b_i = self.b_u(u_indices).squeeze(), self.b_i(i_indices).squeeze()\n",
    "        b_0 = self.b_0.expand_as(b_u)\n",
    "        \n",
    "        activated_intentions = self.get_intention_deltas(u_indices, i_indices)\n",
    "        s_scores = torch.zeros(u_vec.shape[0], self.L, device=u_vec.device)\n",
    "        \n",
    "        # s_ui,l is the sum of intentions from stage l to L\n",
    "        for l in range(1, self.L + 1):\n",
    "            sum_of_intentions = sum(activated_intentions[l-1:])\n",
    "            s_ui_l = b_0 + b_u + b_i + sum_of_intentions\n",
    "            s_scores[:, l-1] = s_ui_l\n",
    "            \n",
    "        return s_scores, activated_intentions\n",
    "\n",
    "\n",
    "# --- EdgeOpt Loss Implementation ---\n",
    "\n",
    "def edge_opt_loss(model, pos_u, pos_i, l_stars, neg_u, neg_i, c_weights):\n",
    "    \n",
    "    # --- POSITIVE Loss Term: log(p_ui, l*) ---\n",
    "    \n",
    "    # Get all scores and intentions for positive samples\n",
    "    pos_s, pos_deltas_plus = model(pos_u, pos_i) \n",
    "    positive_loss = 0\n",
    "    \n",
    "    for idx, l_star in enumerate(l_stars.tolist()):\n",
    "        # delta_plus_l_star is the activated intention at the stopping point l*\n",
    "        # l_star is 1-indexed, use l_star - 1 for list access\n",
    "        delta_plus_l_star = pos_deltas_plus[l_star - 1][idx]\n",
    "        \n",
    "        # p_ui, l* = 1 - exp(-delta_ui, l*+) [cite: 377]\n",
    "        p_l_star = 1 - torch.exp(-delta_plus_l_star)\n",
    "        \n",
    "        # Add log-likelihood (maximized)\n",
    "        positive_loss += torch.log(p_l_star + 1e-8) # Epsilon for stability\n",
    "    \n",
    "    # --- NEGATIVE Loss Term: c * log(1 - P(Purchase)) ---\n",
    "    \n",
    "    # For unobserved negative samples i', l_star is 0. The edge to minimize is l*+1 = 1 (Purchase).\n",
    "    # Get scores for stage 1 (Purchase), which is the first column of the score matrix.\n",
    "    neg_s, _ = model(neg_u, neg_i) \n",
    "    s_neg_purchase = neg_s[:, 0] \n",
    "    \n",
    "    # P(Purchase) = sigma(s_neg_purchase)\n",
    "    p_neg_purchase = torch.sigmoid(s_neg_purchase)\n",
    "\n",
    "    # The negative term is log(1 - P(Purchase)) * c_weights\n",
    "    negative_loss = (c_weights * torch.log(1 - p_neg_purchase + 1e-8)).sum()\n",
    "    \n",
    "    # Total loss to MINIMIZE (negative of the EdgeOpt objective)\n",
    "    total_loss = - (positive_loss.sum() + negative_loss) \n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "# --- B. Comprehensive Evaluation ---\n",
    "from sklearn.metrics import roc_auc_score, ndcg_score\n",
    "\n",
    "def evaluate_ranking_metrics(model, test_pairs, num_items, L):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the primary task: ranking for the most explicit stage L.\n",
    "    test_pairs: list of (u, i, true_label). Assumes unobserved items are the negative class.\n",
    "    L: the index of the most explicit stage (e.g., 4 for Recommend).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. Gather all predicted scores (s_ui, L) and true labels (y_ui, L)\n",
    "    u_list, i_list, true_labels, pred_scores = [], [], [], []\n",
    "    \n",
    "    # Example: Iterating over test users (in real life, batch this)\n",
    "    for u_idx in range(model.user_emb.num_embeddings):\n",
    "        \n",
    "        # Mock: Generate scores for a random subset of items for ranking\n",
    "        test_items = random.sample(range(num_items), 50) \n",
    "        \n",
    "        u_tensor = torch.tensor([u_idx] * len(test_items), dtype=torch.long)\n",
    "        i_tensor = torch.tensor(test_items, dtype=torch.long)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            scores, _ = model(u_tensor, i_tensor)\n",
    "            \n",
    "        # Get score for the last stage L\n",
    "        s_L = scores[:, L - 1].numpy()\n",
    "        \n",
    "        # Mock True Labels (usually loaded from a held-out test set)\n",
    "        # 1 if interaction L was truly observed, 0 otherwise\n",
    "        y_L_true = np.random.randint(0, 2, len(test_items))\n",
    "        \n",
    "        true_labels.extend(y_L_true)\n",
    "        pred_scores.extend(s_L)\n",
    "        \n",
    "    # 2. Calculate Metrics\n",
    "    try:\n",
    "        auc = roc_auc_score(true_labels, pred_scores)\n",
    "    except ValueError:\n",
    "        # AUC fails if only one class is present in the batch\n",
    "        auc = np.nan\n",
    "\n",
    "    # NDCG calculation requires restructuring per user for ranking\n",
    "    # (Simplified NDCG check)\n",
    "    ndcg = np.nan # Requires dedicated per-user ranking implementation\n",
    "\n",
    "    return {'AUC': auc, 'NDCG': ndcg}\n",
    "\n",
    "# --- C. Hyperparameter Tuning (Conceptual) ---\n",
    "\n",
    "def train_and_tune_model(num_users, num_items, num_stages, train_edges, interaction_history, val_data):\n",
    "    \"\"\"\n",
    "    Conceptual framework for hyperparameter search.\n",
    "    \"\"\"\n",
    "    K_VALUES = [16, 32, 64] # [cite: 505]\n",
    "    LR_VALUES = [0.001, 0.005, 0.01]\n",
    "    REG_VALUES = [0.01, 0.05, 0.1] # l2 regularization on embeddings [cite: 389]\n",
    "    NUM_NEGATIVES = 4\n",
    "\n",
    "    best_val_auc = -1\n",
    "    best_params = {}\n",
    "\n",
    "    for K in K_VALUES:\n",
    "        for lr in LR_VALUES:\n",
    "            for reg in REG_VALUES:\n",
    "                \n",
    "                # Setup\n",
    "                model = ChainRecModel(num_users, num_items, num_stages, K=K)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
    "                \n",
    "                # Prepare DataLoader\n",
    "                edge_dataset = EdgeDataset(train_edges)\n",
    "                stagewise_weights = calculate_stagewise_weights(train_edges, num_stages)\n",
    "                \n",
    "                data_loader = DataLoader(\n",
    "                    edge_dataset, \n",
    "                    batch_size=128, \n",
    "                    shuffle=True,\n",
    "                    collate_fn=lambda b: chainrec_collate_fn(b, num_items, interaction_history, NUM_NEGATIVES, stagewise_weights, use_stagewise=True)\n",
    "                )\n",
    "\n",
    "                # --- TRAINING LOOP (Placeholder) ---\n",
    "                for epoch in range(5): # Train for a few epochs\n",
    "                    model.train()\n",
    "                    for pos_u, pos_i, l_stars, neg_u, neg_i, c_weights in data_loader:\n",
    "                        loss = edge_opt_loss(model, pos_u, pos_i, l_stars, neg_u, neg_i, c_weights)\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # --- VALIDATION ---\n",
    "                metrics = evaluate_ranking_metrics(model, val_data, num_items, num_stages)\n",
    "                \n",
    "                if metrics['AUC'] > best_val_auc:\n",
    "                    best_val_auc = metrics['AUC']\n",
    "                    best_params = {'K': K, 'LR': lr, 'REG': reg, 'AUC': best_val_auc}\n",
    "\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    return best_params\n",
    "\n",
    "# --- D & E. Prediction Value Calculation Examples ---\n",
    "\n",
    "def demonstrate_prediction_calculation(model, u_idx, i_idx, num_stages):\n",
    "    \"\"\"\n",
    "    Demonstrates how the score s_ui,l is calculated for specific tasks.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    u_tensor = torch.tensor([u_idx], dtype=torch.long)\n",
    "    i_tensor = torch.tensor([i_idx], dtype=torch.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        s_scores, delta_plus = model(u_tensor, i_tensor)\n",
    "    \n",
    "    print(\"\\n--- Model Internal State (Hypothetical User/Item) ---\")\n",
    "    \n",
    "    # Extracting internal values for visualization\n",
    "    deltas = [d.item() for d in delta_plus]\n",
    "    s_values = [s.item() for s in s_scores.squeeze()]\n",
    "    \n",
    "    print(f\"Activated Intentions (delta+): {deltas}\")\n",
    "    print(f\"Preference Scores (s_l): {s_values}\")\n",
    "    \n",
    "    # 1. Prediction for pairs_Played.csv (Stage 2)\n",
    "    # The pairs_Played.csv task is binary classification: did the user play?\n",
    "    s_played = s_values[1] # s_ui,2 (index 1)\n",
    "    \n",
    "    print(\"\\n--- Prediction for pairs_Played.csv (Stage 2: Play) ---\")\n",
    "    print(f\"Goal: Predict P(Play) = sigma(s_ui,2)\")\n",
    "    print(f\"s_ui,2 (Play) Score: {s_played:.4f}\")\n",
    "    \n",
    "    # Score s_ui,2 = sum(delta+ from Stage 2 to L) + Biases\n",
    "    print(f\"Calculation: s_ui,2 = delta+2 + delta+3 + delta+4 + Biases\") \n",
    "    \n",
    "    # The final prediction is a probability\n",
    "    p_played = torch.sigmoid(torch.tensor(s_played)).item()\n",
    "    print(f\"Prediction Value (P(Play)): {p_played:.4f}\")\n",
    "    print(f\"Classification (Binary): 1 if P(Play) > 0.5, 0 otherwise\")\n",
    "\n",
    "    # 2. Prediction for pairs_Hours.csv (Regression/Transformation)\n",
    "    print(\"\\n--- Prediction for pairs_Hours.csv (Regression/Transformation) ---\")\n",
    "    print(\"chainRec is designed for ranking/classification of binary events, not regression.\")\n",
    "    print(\"To estimate 'hours played' (a continuous value), you would need to:\")\n",
    "    \n",
    "    # Option 1: Use the score as input to a final regression layer (Hybrid Model)\n",
    "    # The score s_ui,2 is strongly correlated with P(Play).\n",
    "    print(f\"1. Use s_ui,2 ({s_played:.4f}) as a feature in a final regression model (e.g., Linear Regression or Neural Network).\")\n",
    "    \n",
    "    # Option 2: Directly model log(Hours) (similar to the paper's 'hours_transformed')\n",
    "    # If the model was trained with a continuous output layer (not EdgeOpt), the final score \n",
    "    # s_ui,2 could represent the transformed hours.\n",
    "    print(f\"2. Assume s_ui,2 is an approximation of the transformed hours (e.g., log(hours)).\")\n",
    "    \n",
    "    # Mock Example (reverse transformation based on log):\n",
    "    mock_transformed_hours = s_played \n",
    "    mock_raw_hours = np.expm1(mock_transformed_hours) # exp(x) - 1\n",
    "    \n",
    "    print(f\"If s_ui,2 = log(hours + 1), then Predicted Hours = exp(s_ui,2) - 1\")\n",
    "    print(f\"Predicted Raw Hours: {mock_raw_hours:.2f}\")\n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Parameters\n",
    "    NUM_STAGES = 4 \n",
    "    K_DEFAULT = 16\n",
    "    \n",
    "    # 1. Data Loading\n",
    "    train_data, interaction_history, NUM_USERS, NUM_ITEMS = load_and_preprocess_data()\n",
    "    val_data = [(0, 105, 0), (1, 106, 0)] # Mock validation set\n",
    "\n",
    "    print(f\"Dataset Stats: {NUM_USERS} users, {NUM_ITEMS} items, {len(train_data)} edges.\")\n",
    "\n",
    "    # 2. Hyperparameter Search (Conceptual)\n",
    "    # best_params = train_and_tune_model(NUM_USERS, NUM_ITEMS, NUM_STAGES, train_data, interaction_history, val_data)\n",
    "    \n",
    "    # 3. Model Initialization (using default K=16)\n",
    "    model = ChainRecModel(NUM_USERS, NUM_ITEMS, NUM_STAGES, K=K_DEFAULT)\n",
    "\n",
    "    # 4. Prediction Demonstrations (Using mock user/item)\n",
    "    \n",
    "    # Note: Model parameters are randomly initialized, so scores are not meaningful yet.\n",
    "    # The example is purely structural to show *which* score is used for *which* task.\n",
    "    demonstrate_prediction_calculation(model, u_idx=0, i_idx=100, num_stages=NUM_STAGES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
