{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b822a699",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### HW 1\n",
    "\n",
    "---\n",
    "\n",
    "**Course:** CSE158 / CSE258 / MGTA461 / DSC256\n",
    "\n",
    "**Term:** Fall 25\n",
    "\n",
    "**Due Date:** 2025-10-13\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae65a359",
   "metadata": {},
   "source": [
    "#### **Regression (week 1)**\n",
    "* *First, using the book review data (see the “runner” code for the exact dataset names), let’s see whether ratings can be predicted as a function of review length, or by using temporal features associated with a review*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb60f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import numpy as np\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3016568d",
   "metadata": {},
   "source": [
    "#### 1. Train a simple predictor that estimates rating from review length:\n",
    "$$\\text{star rating} = \\theta_{0} + \\theta_{1} \\cdot [\\text{review length in charaters}]$$\n",
    "\n",
    "* Rather than using the review length directly, scale the feature to be between 0 and 1 by dividing by the maximum review length in the dataset.\n",
    "* Return the value of $\\theta$ and the Mean Squared Error($MSE$) of your predictor (on the entire dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740cd41a",
   "metadata": {},
   "source": [
    "#### 2. Extend your model to include (in addition to the scaled length) features based on the time of the review. The runner contains code to compute the weekday. \n",
    "* Using a one-hot encoding for the weekday and month, write down feature vectors for the first two examples. \n",
    "* Be careful not to include any redundant dimensions: e.g. your feature vector, including the offset term and the length feature, should contain no more than 19 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00b2ef6",
   "metadata": {},
   "source": [
    "#### 3. Train models that:\n",
    "* Use the weekday and month values directly as features:\n",
    "$$\n",
    "\\text{star rating} \\approx \\theta_{0} + \\theta_{1} \\cdot [\\text{review len in chars}] + \\theta_{2} \\cdot [t.\\text{weekday}()] + \\theta_{3} \\cdot [t.\\text{month}]\n",
    "$$\n",
    "* Use the one-hot encoding from Question 2\n",
    "* Return the Mean Squared Error ($MSE$) of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b901557",
   "metadata": {},
   "source": [
    "#### 4. Repeat the above question, but this time split the data into a training and test set. \n",
    "* You should split the data into 50%/50% train/test fractions following the split used by the code stub (or runner). \n",
    "* After training on the training set, compute the MSE of the two\n",
    "models (the one-hot encoding from Question 2 and the direct encoding from Question 3) on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8582529b",
   "metadata": {},
   "source": [
    "#### **Classification (week 2)**\n",
    "* *Next, using the beer review data, we’ll try to predict ratings (positive or negative) based on characteristics of beer reviews. Load the 50,000 beer review dataset (done in the runner), and construct a label vector by considering whether a review score is four or above*\n",
    "    ```\n",
    "    y = [d['review/overall'] >=4 for d in dataset]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2365bd3",
   "metadata": {},
   "source": [
    "#### 5. Fit a logistic regressor that estimates the binarized score from review length:\n",
    "$$P(\\text{rating is positive}) = \\sigma(\\theta_{0}+\\theta{1}\\cdot[\\text{length}])$$\n",
    "* Use the class `weight=’balanced’` option, compute the number of True Positives, True, Negatives, False Positives, False Negatives, and the Balanced Error Rate of the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172b704d",
   "metadata": {},
   "source": [
    "#### 6. Compute the precision of your classifer for:\n",
    "$$K \\in \\{1,100,1000,10000\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd75c8e",
   "metadata": {},
   "source": [
    "#### 7. Improve your predictor (specifically, reduce the balanced error rate) by incorporating additional features from the data.\n",
    "* e.g. beer styles, ratings, features from text, etc.\n",
    "* The BER should be ~3% higher than the solution from Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb83329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
